{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75debf70-1fbe-4ced-84be-1871e8dfe018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "matplotlib.use('Agg')\n",
    "# 画像ディレクトリのパス\n",
    "image_dir = 'data/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed6efe-f24a-44f6-8831-44f89be948e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここで既存のモデルを読み込む\n",
    "model_file = 'linear.h5'\n",
    "\n",
    "model = tf.keras.models.load_model(model_file)\n",
    "# 評価モードに設定\n",
    "model.trainable = False\n",
    "model.summary()\n",
    "number_of_layers = len(model.layers)\n",
    "\n",
    "def load_img(path):\n",
    "    # テスト用の画像を読み込む\n",
    "    img = tf.keras.preprocessing.image.load_img(path)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01856b-6d8c-4aba-9566-ea5ce97e7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一度だけ全ての中間層の出力を取得するモデルを作成\n",
    "all_layer_outputs = [layer.output for layer in model.layers if not isinstance(layer, tf.keras.layers.Dropout)]\n",
    "activation_model = Model(inputs=model.input, outputs=all_layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0899f4e-b0fe-41ee-9e14-77a685c8e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cnn_activations(img_array):\n",
    "    # 全ての中間層の出力を一度に取得\n",
    "    # ただし、結果として(活性化, レイヤー名)のペアをリストに格納\n",
    "    activations_and_names = []\n",
    "    for layer in model.layers:\n",
    "        if not isinstance(layer, tf.keras.layers.Dropout):\n",
    "            layer_output = layer.output\n",
    "            activation_model = Model(inputs=model.input, outputs=layer_output)\n",
    "            activations = activation_model.predict(img_array)\n",
    "            activations_and_names.append((activations, layer.name))\n",
    "    return activations_and_names\n",
    "\n",
    "def get_all_activations(img_array):\n",
    "    # 全ての中間層の出力を一度に取得\n",
    "    activations_list = activation_model.predict(img_array)\n",
    "    # 各層の名前を取得\n",
    "    layer_names = [layer.name for layer in model.layers if not isinstance(layer, tf.keras.layers.Dropout)]\n",
    "    # (活性化, レイヤー名)のペアをリストに格納\n",
    "    activations_and_names = list(zip(activations_list, layer_names))\n",
    "    return activations_and_names\n",
    "\n",
    "def get_activated_image(img_array, file_id):\n",
    "    # 元の画像を描画用に準備\n",
    "    original_img = img_array[0].astype(np.uint8)\n",
    "    # 描画するレイヤーの数をカウント\n",
    "    all_activations_and_names = get_all_activations(img_array)\n",
    "    count = sum(1 for (activations, layer_name) in all_activations_and_names if len(activations.shape) == 4)\n",
    "    rows = count + 1  # +1 はオリジナル画像のため\n",
    "    current_row = 1  # 現在の行数\n",
    "    # 画像のリストを初期化\n",
    "    images_to_combine = []\n",
    "    # 各フィルタの活性化を表示する\n",
    "    current_row = 1\n",
    "    # 描画の準備\n",
    "    fig = plt.figure(figsize=(20, rows), facecolor='white')  # 背景色を白に設定\n",
    "\n",
    "    for activations, layer_name in all_activations_and_names:\n",
    "        if len(activations.shape) == 4:\n",
    "            n_filters = activations.shape[-1]\n",
    "            combined_activation = activations[0, :, :, 0]\n",
    "\n",
    "            side = int(np.ceil(np.sqrt(n_filters)))\n",
    "\n",
    "            # オリジナルの画像サイズにリサイズするための準備\n",
    "            resized_activations = []\n",
    "\n",
    "            # 各フィルタの活性化をオリジナルの画像サイズにリサイズ\n",
    "            for j in range(n_filters):\n",
    "                resized_activation = cv2.resize(activations[0, :, :, j], (original_img.shape[1], original_img.shape[0]))\n",
    "                resized_activations.append(resized_activation)\n",
    "\n",
    "            # リサイズされた活性化を平均化\n",
    "            combined_activation = np.mean(resized_activations, axis=0)\n",
    "            heatmap = (combined_activation - np.min(combined_activation)) / (np.max(combined_activation) - np.min(combined_activation))\n",
    "\n",
    "            heatmap_img = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "            heatmap_img = cv2.cvtColor(heatmap_img, cv2.COLOR_BGR2RGB)\n",
    "            overlay_img = heatmap_img\n",
    "            #overlay_img  = cv2.addWeighted(original_img, 0.6, heatmap_img, 0.4, 0)\n",
    "            \n",
    "            ax = fig.add_subplot(rows, 1, current_row)\n",
    "            ax.imshow(overlay_img)\n",
    "            ax.axis('off')\n",
    "            ax.set_facecolor('white')  # サブプロットの背景色を白に設定\n",
    "        \n",
    "            # レイヤー名を画像の左端にサブプロットのタイトルとして追加\n",
    "            ax.set_title(f\"Layer - {layer_name}\", loc='left')\n",
    "            \n",
    "            current_row += 1\n",
    "\n",
    "    # ループの後にオリジナル画像を追加\n",
    "    ax = fig.add_subplot(rows, 1, current_row)\n",
    "    ax.imshow(original_img)\n",
    "    ax.axis('off')\n",
    "    ax.set_facecolor('white')  # サブプロットの背景色を白に設定\n",
    "    ax.set_title(f\"Original Image: {file_id}\", loc='left')\n",
    "    fig.tight_layout()\n",
    "    # 描画内容をnumpy配列に変換\n",
    "    canvas = fig.canvas\n",
    "    canvas.draw()\n",
    "    img_arr = np.array(canvas.renderer.buffer_rgba())[:, :, :3]  # RGBAからRGBに変換\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return img_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ced09-4a0f-482a-b155-fd6af643779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio_ffmpeg as ffmpeg\n",
    "\n",
    "# ファイル名からレコードIDを抽出する関数\n",
    "def get_record_id_from_filename(filename):\n",
    "    return int(filename.split('_')[0])\n",
    "\n",
    "# 画像ディレクトリ内の全ファイルのリストを取得\n",
    "image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "\n",
    "# レコードIDに基づいてファイル名をソート\n",
    "image_files_sorted = sorted(image_files, key=get_record_id_from_filename)\n",
    "\n",
    "start = 0\n",
    "end = 500\n",
    "count = 0\n",
    "t1_total = 0\n",
    "t2_total = 0\n",
    "start_time = time.time()\n",
    "writer_type = \"ffmpeg\"\n",
    "#writer_type = \"opencv\"\n",
    "# 各画像ファイルに対して処理を行う\n",
    "files_to_process = image_files_sorted[start:end]\n",
    "try:\n",
    "    for image_file in tqdm(files_to_process, total=len(files_to_process), desc=\"Processing Images\"):\n",
    "        t1 = time.time()\n",
    "        img_path = os.path.join(image_dir, image_file)\n",
    "        img_array = load_img(img_path)\n",
    "        file_id = get_record_id_from_filename(image_file)\n",
    "        img_rgb = get_activated_image(img_array, file_id)\n",
    "        t1_total += time.time() - t1\n",
    "        if count == 0:\n",
    "            frame_height, frame_width, _ = img_rgb.shape\n",
    "            figsize = (frame_width / 100, frame_height / 100)\n",
    "            default_dpi = plt.rcParams['figure.dpi']\n",
    "            plt.figure(figsize=figsize, dpi=default_dpi)\n",
    "            # OpenCVの画像をmatplotlibで表示\n",
    "            plt.imshow(img_rgb)\n",
    "            plt.axis('off')  # 軸を非表示にする\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            # 出力動画の設定\n",
    "            fps = 30.0  # 動画のフレームレート。必要に応じて変更してください。\n",
    "            movie_file =  os.path.splitext(model_file)[0] + '.mp4'\n",
    "            if writer_type == \"ffmpeg\":\n",
    "                writer = ffmpeg.write_frames(movie_file, (frame_width, frame_height), codec='libx264', fps=fps)\n",
    "                writer.send(None)  # Seed the writer\n",
    "            elif writer_type == \"opencv\":\n",
    "                # 出力動画の設定\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MP4用のコーデック\n",
    "                writer = cv2.VideoWriter(movie_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        t2 = time.time()\n",
    "        # 動画ファイルを作成する\n",
    "        if writer_type == \"ffmpeg\":\n",
    "            img_rgb_contiguous = np.ascontiguousarray(img_rgb)\n",
    "            writer.send(img_rgb_contiguous)\n",
    "        elif writer_type == \"opencv\":\n",
    "            img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
    "            writer.write(img_bgr)\n",
    "        t2_total += time.time() - t2\n",
    "        count += 1\n",
    "\n",
    "finally:\n",
    "    # 動画の書き込みを終了\n",
    "    if writer_type == \"ffmpeg\":\n",
    "        writer.close()\n",
    "    elif writer_type == \"opencv\":\n",
    "        writer.release()\n",
    "\n",
    "print(f\"end: {time.time() - start_time:.2f} sec, t1: {t1_total} sec, t2: {t2_total} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06226745-6a48-4f47-abe5-d9a070a6a116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc31af-9e8e-41d2-bb69-63ffaaa04bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6bdee4-9471-422a-8056-52eeb6267039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
